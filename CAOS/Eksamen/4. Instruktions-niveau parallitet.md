Hvad compileren kan gøre og ikke kan gøre

# Pipelining Principper
* hvor lang tid tager en instruktion i et kredsløb
	* fx kan man have noget kombinatorisk logik der tager 300 ps (pico sekunder) og 20 ps for gemme resultatet i et register 
	* Derfor tager perioden på clock cyklus skal være mindst 320 ps
* et andet eksempel ![[Pasted image 20230514114449.png]]

* Pipeline Diagrammer kan se forskellige ud, men hovedsageligt er den sekventiel eller flere trins pipeline
	* sekventiel: ![[Pasted image 20230514114804.png]]
	* flere trins: ![[Pasted image 20230514114818.png]]
* flere trin gøre at man kan lave flere operationer på samme tid, men kun en per trin

### Udførelse af en pipeline
![[Pasted image 20230514115015.png]]
![[Pasted image 20230514115043.png]]
![[Pasted image 20230514115056.png]]
![[Pasted image 20230514115110.png]]
![[Pasted image 20230514115124.png]]

## Problemer med flere trin
* Der kommer et problem når der er forskellige størrelser i et trin
	* Det sker da nogen beregninger kræver mere end andre
	* produktiviteten bestemmes af det langsommeste trin
	* hvilket gør at de andre trin ligger stille imens
* Der er også problemet med for mange trin
	* for jo flere trin, jo mere tid skal bruges til at indlæsning af registre

 * Y86-SEQ har 5 trin med fem registre (F, D, E, M, W)![[Pasted image 20230514120516.png]]

* Der kan ske problemer hvis et trin er igang med at skulle skrive til et register samtidig med at der er et trin som skal læse det samme register 
	* Det medføre at der opstår stalling, hvor man holder instruktionen tilbage og forsøger igen i næste cyklus 
	* så bliver der lavet en boble ![[Pasted image 20230514130253.png]]

## Ydeevne / optimering
* clock rate/frekvens, samt raten instruktioner udføres med er matrikkerne for ydeevne 
	* clock rate måles i gigahertz 
	* raten af instruktioner måles i CPI: cycler per instruktion 
		* altså gennemsnittet af hvor mange clock cycler kræver hver instruktion

### CPI
* CPI må ligge tæt på 1.0
	* aka ny instruktion hver clock cyclus og afslutter hver cyklus
* Hvis CPI > 1.0 betyder det at der forkommer stalls eller annullere instruktioner
* beregning af CPI (CPI = C/I = (I+B)/I = 1.0 + B/I)
	* C = clock cycler brugt (C = I + B)
	* I = instruktioner er færdigbehandlede 
	* B = bobler indskudt 
* $$CPI=C/I=(I+B)/I=1.0+B/I$$
* B/I er faktoren der repræsenterer den gennemsnitlige straf forårsaget af bobler  
	* B/I = LP + MP + RP ![[Pasted image 20230514130520.png]]

# Compiler optimeringer 
* I sagen kerne omhandler det om at oversætte programmet til maskinen så den kan udnyttes effektivt 
	* det er bl.a. register allokering, schedulering, eliminate dead code, osv.
* compiler ændre normalt ikke asymptotisk kompleksitet
	* hvilke algoritmer der er blevet brugt, så Store-O er stadig end samme

### Begrænsninger 
* compileren må ikke ændre programmets adfærd
	* Det vil sige at det optimeredet program skal gøre præcist det samme som det oprindelige program

## Optimeringer 
* almene optimeringer 
	* kode flytning 
		* reducerer hyppigheden af den beregning 
		* hvis beregningen altid giver det samme, så bør den kun beregnes en gang
		* flyt kode ud af løkker hvis muligt 

* Erstat dyre operationer med nogen der er billegere
	* fx istedet for mult og division, brug shift, add

* genbrug resultat fra dele udtryk, hvis det er muligt. Eksempel:![[Pasted image 20230514142253.png]]

* visualisering af at tage kaldet strlen ud af løkken: ![[Pasted image 20230514142458.png]]
	* compileren vil ikke selv gøre det, for det ville kunne lave side effekter og give andre resultater 

* funktions in-lining: erstat kalds stedet med kopi af funktionskroppen (manulet eller compiler) 
	* for små funktioner giver anledning til relativt stort over head via CALL og RET
	* åbner op for andre optimerings muligheder

# Parallelisme 
Det bliver gået mere i dybten fra slide 48 i lektion 7, men her er det overordnet
* CPE = cycles per OP, jo mindre jo bedre
	* ved at lave grundlæggende optimeringer kan man ofte se et stort fald i CPE![[Pasted image 20230514144957.png]]
	* udfoldninger af løkker kan hjælpe på at få CPE til at flade Især hvis man laver Reassociering ![[Pasted image 20230514145350.png]]

* ideen bag udfoldning og akkumulering 
	* er at vi kan udfolde til enhver grad L
	* vi kan akkumulere K resultater parallelt 
	* L skal være et produkt af K
	* LxK unrolling

* det laver aftagende udbytte 
	* Stort overhead ved korte vektorer![[Pasted image 20230514151455.png]]

men generelt kan man se store hastigheds forbedringer med alle de givne muligheder (eksemplet er 20 gange hurtigere end det standart -O1 compilering)


## Virkeligheden omkring ydeevne 
![[Pasted image 20230514151956.png]]
* hvordan man skal optimere ![[Pasted image 20230514152030.png]]






 